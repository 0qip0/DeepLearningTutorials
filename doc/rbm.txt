.. _RBM:

Restricted Boltzmann Machines (RBM)
===================================


.. note::
    The code for this section is available for download `here`_.

.. _here: http://deeplearning.net/tutorial/code/rbm.py



Energy-Based Models (EBM)
+++++++++++++++++++++++++

**Energy-based** models associate a scalar energy to each configuration of the
variables of interest. Learning corresponds to modifying that energy function
so that its shape has desirable properties. For example, we would like
plausible or desirable configurations to have low energy.  Energy-based
probabilistic models define a probability distribution through an energy
function, as follows:

.. math::
  :label: energy1

  p(x) = \frac {e^{-E(x)}} {Z}.

The normalizing factor :math:`Z` is called the **partition function** by analogy
with physical systems.

.. math::
    Z = \sum_x e^{-E(x)}

An energy-based model can be learnt by performing (stochastic) gradient
descent on the empirical log-likelihood of the training data:

.. math::
    \mathcal{L}(\theta, \mathcal{D}) = \frac{1}{N} \sum_{x^{(i)} \in
    \mathcal{D}} log\ p(x^{(i)}).

using the stochastic gradient :math:`\frac{\partial p(x^{(i)})}{\partial
\theta}`, where :math:`\theta` are the parameters of the model.


**EBMs with Hidden Units**

In many cases of interest, we do not observe the example :math:`x` fully, or we
want to introduce some non-observed variables to increase the expressive power
of the model. So we consider an observed part (still denoted :math:`x` here) and a
**hidden** part :math:`h`. We can then write:

.. math::
  :label: energy2

   P(x) = \sum_h P(x,h) = \sum_h \frac{e^{-E(x,h)}}{Z}.

In such cases, to map this formulation to one similar to Eq. :eq:`energy1`, we
introduce the notation (inspired from physics) of **free energy**, defined as
follows:

.. math::
   :label: free_energy

    \mathcal{F}(x) = - \log \sum_h e^{-E(x,h)}

which allows us to write,

.. math::
    &P(x) = \frac{e^{-\mathcal{F}(x)}}{Z} \text{ with } Z=\sum_x e^{-\mathcal{F}(x)}.

The data log-likelihood gradient then has a particularly interesting form.

.. math::
  \frac{\partial log p(x)}{\partial \theta}
   &= - \frac{\partial \mathcal{F}(x)}{\partial \theta} + 
         \sum_{\tilde{x}} p(\tilde{x}) \
             \frac{\partial \mathcal{F}(\tilde{x})}{\partial \theta}.

Notice that the above gradient contains two terms, which are referred to as
the **positive** and **negative phase**. The terms positive and negative do
not refer to the sign of each term in the equation, but rather reflect their
effect on the probability density defined by the model. The first term
increases the probability of training data (by reducing the corresponding free
energy), while the second term decreases the probability of samples generated
by the model.

It is usually difficult to determine this gradient analytically, as it
involves the computation of 
:math:`E_P [ \frac{\partial \mathcal{F}(x)} {\partial \theta} ]`. This is
nothing less than an expectation over all possible configurations of the input
:math:`x` (under the distribution :math:`P` formed by the model) !

The first step in making this computation tractable is to estimate the
expectation using a fixed number of model samples. Samples used to estimate the
negative phase gradient are referred to as **negative particles**, which are
denoted as :math:`\mathcal{N}`. The gradient can then be written as:

.. math::
  \frac{\partial log p(x)}{\partial \theta}
   &\approx 
   - \frac{\partial \mathcal{F}(x)}{\partial \theta} + 
     \sum_{\tilde{x} \in \mathcal{N}} p(\tilde{x}) \
     \frac{\partial \mathcal{F}(\tilde{x})}{\partial \theta}.

With the above formula, we almost have a pratical, stochastic algorithm for
learning an EBM. The only missing ingredient is how to extract these negative
particles :math:`\mathcal{N}`. While the statistical litterature abounds with
sampling methods, Markov Chain Monte Carlo methods are especially well suited
for models such as the Restricted Boltzmann Machines (RBM), a specific type of
EBM.


Restricted Boltzmann Machines (RBM)
+++++++++++++++++++++++++++++++++++

Boltzmann Machines (BMs) are a particular form of energy-based model which
contain hidden variables. Restricted Boltzmann Machines further restrict BMs to
those without visible-visible and hidden-hidden connections.  A graphical
depiction of an RBM is shown below.

.. image:: images/rbm.png
    :align: center

The energy function :math:`E(x,h)` of an RBM is defined as:

.. math::
    :label: rbm_energy

    E(v,h) = - b'x - c'h - h'Wx 

where :math:`W` represents the weights connecting hidden and visible units and
:math:`b`, :math:`c` are the offsets of the visible and hidden layers
respectively.

This translates directly to the following free energy formula:

.. math::
  \mathcal{F}(x)= - b'x - \sum_i log \sum_{h_i} e^{h_i (c_i + W_i x)}.

Because of the specific structure of RBMs, visible and hidden units are
conditionally independent given one-another. Using this property, we can
write:

.. math::
    p(h|x) &= \prod_i p(h_i|x) \\
    p(x|h) &= \prod_j p(x_j|h).

**RBMs with binary units**

In the commonly studied case of using binary units (where :math:`h_i \in
\{0,1\}`, we obtain from Eq. :eq:`rbm_energy` and :eq:`energy2`, a stochastic
version of the usual neuron activation function:

.. math::
  P(h_i=1|x) = sigm(c_i + W_i x) \\
  P(x_j=1|h) = sigm(b_j + W'_j h)

The free energy of an RBM with binary units further simplifies to:

.. math::
  \mathcal{F}(x)= - b'x - \sum_i log 1 + e^{(c_i + W_i x)}.


Sampling in an RBM
++++++++++++++++++

Samples of :math:`p(x)` can be obtained by running a Markov chain to
convergence, using Gibbs sampling as the transition operator.

Gibbs sampling of the joint of N random variables :math:`S=(S_1, ... , S_N)`
is done through a sequence of N sampling sub-steps of the form 
:math:`S_i \sim p(S_i | S_{-i})` where :math:`S_{-i}` contains the :math:`N-1`
other random variables in :math:`S` excluding :math:`S_i`.

For RBMs, :math:`S` consists of the set of visible and hidden units. However,
since they are conditionally independent, one can perform block Gibbs
sampling. In this setting, visible units are sampled simultaneously given
fixed values of the hidden units. Similarly, hidden units are sampled
simultaneously given the visibles. A step in the Markov chain is thus taken as
follows: 

.. math::
    h^{(n+1)} &\sim sigm(W'x^{(n)} + c) \\
    x^{(n+1)} &\sim sigm(W h^{(n+1)} + b),

where :math:`h^{(n)}` refers to the set of all hidden units at the n-th step of
within the Markov chain.

This can be illustrated graphically:

.. image:: images/markov_chain.png
    :align: center

As :math:`t \rightarrow \infty`, samples :math:`(x^{(t)}, h^{(t)})` are
guaranteed to be accurate samples of :math:`p(x,h)`.

In theory, each parameter update in the learning process would require running
one such chain to convergence. It is needless to say that doing so would be
prohibitively expensive. As such, several algorithms have been devised for
RBMs, in order to efficiently sample from :math:`p(x,h)` during the learning
process.


Contrastive Divergence (CD-k)
-----------------------------

Contrastive Divergence uses two tricks to speed up the sampling process:

* since we eventually want :math:`p(x) \approx p_T(x)` (the true, underlying
  distribution of the data), we initialize the Markov chain with a training
  example.
  
* CD does not wait for the chain to converge. Samples are obtained after only
  k-steps of Gibbs sampling. In pratice, :math:`k=1` has been shown to work
  surprisingly well.


Persistent CD
-------------

Persistent CD [Tieleman08]_ uses another approximation for sampling from
:math:`p(x,h)`.  It relies on a single Markov chain, which has a persistent
state. For each parameter update, we extract new samples by simply running the
chain for k-steps. The state of the chain is then preserved for subsequent updates.

The general intuition is that if parameter updates are small enough compared
to the mixing rate of the chain, the Markov chain should be able to "catch up"
to changes in the model.


Implementation
++++++++++++++

We construct a ``RBM`` class. The constructor has to initialize all 
parameters of the network, or to get them as arguments. The second
option is usefull when a RBM is used in a deep network, 
case in which the weight matrix and the hidden layer bias has to be 
shared with the corresponding sigmoidal layer of a mlp network.

.. code-block:: python

  class RBM(object):
    """Restricted Boltzmann Machine (RBM) """
    def __init__(self, input=None, n_visible=784, n_hidden=500, \
        W = None, hbias = None, vbias = None, numpy_rng = None, 
        theano_rng = None):
        """ 
        RBM constructor. Defines the parameters of the model along with
        basic operations for inferring hidden from visible (and vice-versa), 
        as well as for performing CD updates.

        :param input: None for standalone RBMs or symbolic variable if RBM is
        part of a larger graph.

        :param n_visible: number of visible units

        :param n_hidden: number of hidden units

        :param W: None for standalone RBMs or symbolic variable pointing to a
        shared weight matrix in case RBM is part of a DBN network; in a DBN,
        the weights are shared between RBMs and layers of a MLP

        :param hbias: None for standalone RBMs or symbolic variable pointing 
        to a shared hidden units bias vector in case RBM is part of a 
        different network

        :param vbias: None for standalone RBMs or a symbolic variable 
        pointing to a shared visible units bias
        """

        self.n_visible = n_visible
        self.n_hidden  = n_hidden


        if W is None : 
           # W is initialized with `initial_W` which is uniformely sampled
           # from -6./sqrt(n_visible+n_hidden) and 6./sqrt(n_hidden+n_visible)
           # the output of uniform if converted using asarray to dtype 
           # theano.config.floatX so that the code is runable on GPU
           initial_W = numpy.asarray( numpy.random.uniform( 
                     low = -numpy.sqrt(6./(n_hidden+n_visible)), 
                     high = numpy.sqrt(6./(n_hidden+n_visible)), 
                     size = (n_visible, n_hidden)), 
                     dtype = theano.config.floatX)
           # theano shared variables for weights and biases
           W = theano.shared(value = initial_W, name = 'W')

        if hbias is None :
           # create shared variable for hidden units bias
           hbias = theano.shared(value = numpy.zeros(n_hidden, 
                               dtype = theano.config.floatX), name='hbias')

        if vbias is None :
            # create shared variable for visible units bias
            vbias = theano.shared(value =numpy.zeros(n_visible, 
                                dtype = theano.config.floatX),name='vbias')

        if numpy_rng is None:    
            # create a number generator 
            numpy_rng = numpy.random.RandomState(1234)

        if theano_rng is None : 
            theano_rng = RandomStreams(numpy_rng.randint(2**30))


        # initialize input layer for standalone RBM or layer0 of DBN
        self.input = input if input else T.dmatrix('input')

        self.W          = W
        self.hbias      = hbias
        self.vbias      = vbias
        self.theano_rng = theano_rng
        # **** WARNING: It is not a good idea to put things in this list 
        # other than shared variables created in this function.
        self.params     = [self.W, self.hbias, self.vbias]
        self.batch_size = self.input.shape[0]

Next step is to add a Gibbs sampling function to our class. Since we are 
going to use only CD-1 in this tutorial we need to implement just one 
step of Gibbs sampling. The following function does this, by first 
sample the hidden, and afterwards sampling the visible.

.. code-block:: python

    def gibbs_1(self, v0_sample):
        ''' This function implements one step of Gibbs sampling '''
        # compute the activation of the hidden units given a sample of the
        # vissibles
        h0_mean = T.nnet.sigmoid(T.dot(v0_sample, self.W) + self.hbias)
        # get a sample of the hiddens given their activation
        h0_sample = self.theano_rng.binomial(size = h0_mean.shape, n = 1, 
                                                            prob = h0_mean)
        # compute the activation of the visible given the hidden sample
        v1_mean = T.nnet.sigmoid(T.dot(h0_sample, self.W.T) + self.vbias)
        # get a sample of the visible given their activation
        v1_sample = self.theano_rng.binomial(size = v1_mean.shape, n = 1, 
                                                            prob = v1_mean)
        return [v1_mean, v1_sample]
 

We also need to add a ``cd`` method to the class that gives as the CD-1 
updates :

.. code-block:: python

    def cd(self, lr = 0.1, persistent=None):
        """ This functions implements one step of CD-1

        :param lr: learning rate used to train the RBM

        Return a tuple of values describing a CD step. The first value 
        in the tuple is the reconstruction cross-entropy cost, a proxy 
        to what CD tries to minimize, while the second is an update 
        dictionary. The dictionary contains the update rules for weights
        and biases but also an update of the shared variable used to store
        the persistent chain, if one is used.
        
        Note that the reconstruction cross-entropy cost is just
        a proxy of what CD actually tries to minimize, do not confuse the 
        two.

        If persistent is None, it defaults to self.input

        CD aka CD1 - cd()
        PCD        - cd(persistent=shared(numpy.asarray(initializer)))
        """

        if persistent is None:
            chain_start = self.input
        else:
            chain_start = persistent


Note that ``cd`` takes as argument a variable called persistent. This
should point to where we left off the Gibbs chain in the previous call if
we are to use PCD instead of CD, otherwise we initialize the input of
the chain with our last observarion. Given that we know the starting 
point of the chain, we can go ahead and compute the values of the
visibles and hiddens in the negative and positive phase, values needed
to compute the gradient of the parameters

.. code-block:: python


        # define the graph for positive phase
        ph_act    = T.dot(chain_start, self.W) + self.hbias
        ph_mean   = T.nnet.sigmoid(ph_act)
        ph_sample = self.theano_rng.binomial(size = ph_mean.shape, n = 1,
                                                         prob = ph_mean)

        # define the graph for the negative phase
        nv_act    = T.dot(ph_sample, self.W.T) + self.vbias
        nv_mean   = T.nnet.sigmoid(nv_act)
        nv_sample = self.theano_rng.binomial(size = nv_mean.shape, n = 1,
                                                         prob = nv_mean)
        nh_act    = T.dot(nv_sample, self.W) + self.hbias
        nh_mean   = T.nnet.sigmoid(nh_act)
        nh_sample = self.theano_rng.binomial(size = nh_mean.shape, n = 1,
                                                         prob = nh_mean)


        g_vbias = T.sum( self.input - nv_mean, axis = 0)/self.batch_size
        g_hbias = T.sum( ph_mean    - nh_mean, axis = 0)/self.batch_size
        g_W = T.dot(ph_mean.T, self.input   )/ self.batch_size - \
              T.dot(nh_mean.T, nv_mean      )/ self.batch_size

        gparams = [g_W.T, g_hbias, g_vbias]

Finally, we compute the reconstruction cross-entropy cost, which can be 
seen as a proxy to the function minimized by CD.  While this value is 
not used anywhere, it is a good indicative that our network is learning.
We also construct the update dictionary, that in case of PCD,
should update the shared variable pointing the end of the chain.

.. code-block:: python

        cross_entropy = T.mean(T.sum( self.input*T.log(nv_mean) 
                       + (1 - self.input)*T.log(1-nv_mean), axis = 1))

        # constructs the update dictionary
        updates = {}
        for gparam, param in zip(gparams, self.params):
           updates[param] = param + gparam * lr

        if persistent:
            # Note that this works only if persistent is a shared variable
            updates[persistent] = nv_sample


        return (cross_entropy, updates)


Given that we have the update rule of the network, training is easy. But
before going over the training loop we need some more utility 
functions. RBMs are generative models, and once trained we want to be 
able to sample them, plot the samples and look at them. We also want to 
be able to plot the weights to see what it learned. This technique of
visualizing the weights can be quite insightful but bare in mind that it
does not provide the entire story, since we neglect the biases, and we 
scale the weights such that we convert them to values between 0 and 1. 

To plot a sample, what we need to do is to take the visible units, which 
are a flattened image (there is no 2D structure to the visible units,
just a 1D string of nodes) and reshape it into a 2D image. The order in
which the points from the 1D array go into the 2D image is given by the 
order in which the inital MNIST images where converted into a 1D array.
Lucky for us this is just a call of the ``numpy.reshape`` function.

Plotting the weights is a bit more tricky. We have ``n_hidden`` hidden
units, each of them corresponding to a column of the weight matrix. A 
column has the same shape as the visible, where the weight corresponding 
to the connection with visible unit `j` is at position `j`. Therefore,
if we reshape every such column, using ``numpy.reshape``, we get a
filter image that tells us how this hidden unit is influenced by 
the input image.

We need a utility function that takes a minibatch, or the weight matrix, 
and converts each row ( for the weight matrix we do a transpose ) into a 
2D image and then tile this images together.  Once we converted the
minibatch or the weights in this image of tiles, we can use PIL to plot 
and save. `PIL <http://www.pythonware.com/products/pil/>`_ is a standard 
python libarary to deal with images.

Tiling minibatches together is done for us by 
``tile_raster_image`` function which we provide here. 

.. code-block:: python


  def scale_to_unit_interval(ndar,eps=1e-8):
    """ Scales all values in the ndarray ndar to be between 0 and 1 """
    ndar = ndar.copy()
    ndar -= ndar.min()
    ndar *= 1.0 / (ndar.max()+eps)
    return ndar


  def tile_raster_images(X, img_shape, tile_shape,tile_spacing = (0,0), 
              scale_rows_to_unit_interval = True, output_pixel_vals = True):
    """
    Transform an array with one flattened image per row, into an array in 
    which images are reshaped and layed out like tiles on a floor.

    This function is useful for visualizing datasets whose rows are images, 
    and also columns of matrices for transforming those rows 
    (such as the first layer of a neural net).

    :type X: a 2-D ndarray or a tuple of 4 channels, elements of which can 
    be 2-D ndarrays or None;
    :param X: a 2-D array in which every row is a flattened image.

    :type img_shape: tuple; (height, width)
    :param img_shape: the original shape of each image

    :type tile_shape: tuple; (rows, cols)
    :param tile_shape: the number of images to tile (rows, cols)
    
    :param output_pixel_vals: if output should be pixel values (i.e. int8
    values) or floats

    :param scale_rows_to_unit_interval: if the values need to be scaled before
    being plotted to [0,1] or not


    :returns: array suitable for viewing as an image.  
    (See:`PIL.Image.fromarray`.)
    :rtype: a 2-d array with same dtype as X.

    """
 
    assert len(img_shape) == 2
    assert len(tile_shape) == 2
    assert len(tile_spacing) == 2

    # The expression below can be re-written in a more C style as 
    # follows : 
    #
    # out_shape    = [0,0]
    # out_shape[0] = (img_shape[0]+tile_spacing[0])*tile_shape[0] -
    #                tile_spacing[0]
    # out_shape[1] = (img_shape[1]+tile_spacing[1])*tile_shape[1] -
    #                tile_spacing[1]
    out_shape = [(ishp + tsp) * tshp - tsp for ishp, tshp, tsp 
                        in zip(img_shape, tile_shape, tile_spacing)]

    if isinstance(X, tuple):
        assert len(X) == 4
        # Create an output numpy ndarray to store the image 
        if output_pixel_vals:
            out_array = numpy.zeros((out_shape[0], out_shape[1], 4), dtype='uint8')
        else:
            out_array = numpy.zeros((out_shape[0], out_shape[1], 4), dtype=X.dtype)

        #colors default to 0, alpha defaults to 1 (opaque)
        if output_pixel_vals:
            channel_defaults = [0,0,0,255]
        else:
            channel_defaults = [0.,0.,0.,1.]

        for i in xrange(4):
            if X[i] is None:
                # if channel is None, fill it with zeros of the correct 
                # dtype
                out_array[:,:,i] = numpy.zeros(out_shape,
                        dtype='uint8' if output_pixel_vals else out_array.dtype
                        )+channel_defaults[i]
            else:
                # use a recurrent call to compute the channel and store it 
                # in the output
                out_array[:,:,i] = tile_raster_images(X[i], img_shape, tile_shape, tile_spacing, scale_rows_to_unit_interval, output_pixel_vals)
        return out_array

    else:
        # if we are dealing with only one channel 
        H, W = img_shape
        Hs, Ws = tile_spacing

        # generate a matrix to store the output
        out_array = numpy.zeros(out_shape, dtype='uint8' if output_pixel_vals else X.dtype)


        for tile_row in xrange(tile_shape[0]):
            for tile_col in xrange(tile_shape[1]):
                if tile_row * tile_shape[1] + tile_col < X.shape[0]:
                    if scale_rows_to_unit_interval:
                        # if we should scale values to be between 0 and 1 
                        # do this by calling the `scale_to_unit_interval`
                        # function
                        this_img = scale_to_unit_interval(X[tile_row * tile_shape[1] + tile_col].reshape(img_shape))
                    else:
                        this_img = X[tile_row * tile_shape[1] + tile_col].reshape(img_shape)
                    # add the slice to the corresponding position in the 
                    # output array
                    out_array[
                        tile_row * (H+Hs):tile_row*(H+Hs)+H,
                        tile_col * (W+Ws):tile_col*(W+Ws)+W
                        ] \
                        = this_img * (255 if output_pixel_vals else 1)
        return out_array


Having this utility function, we can start training, saving the filters
(weight plots) after each training epoch.


.. code-block:: python

    for epoch in xrange(training_epochs):
        # go through the training set
        c = []
        for batch_index in xrange(n_train_batches):
           c += [ train_rbm(batch_index) ]
        print 'Training epoch %d, average cross-entropy reconstruction cost '%epoch, numpy.mean(c)
        plotting_start = time.clock()
        #           Plot filters after each training epoch
        # Construct image from the weight matrix 
        image = PIL.Image.fromarray(tile_raster_images( X = rbm.W.value.T,
                 img_shape = (28,28),tile_shape = (10,10), 
                 tile_spacing=(1,1)))
        image.save('filters_at_epoch_%i.png'%epoch) 
        plotting_stop = time.clock()
        plotting_time += (plotting_stop - plotting_start)
    end_time = time.clock()

    pretraining_time = (end_time - start_time) - plotting_time

    print ('Training took %f minutes' %(pretraining_time/60.))



Now for sampling we need to use the ``gibbs_1`` and PCD to have better 
results. For this we first pick several samples (from the testing sequence, 
though we could as well pick it from the training set) to initialize 
several chains that we would sample. 


.. code-block:: python

    # Sampling the RBM

    # Initialize the persistent chain with some sample from the test 

    # find out the number of test samples  
    number_of_test_samples = test_set_x.value.shape[0]

    # pick one randomly
    sample = rng.randint(number_of_test_samples-20)

    # initialize 20 persistent chains in parallel
    persistent_chain = theano.shared( test_set_x.value[sample:sample+20])



Next we create the 20 persistent chains in paralel to get our
samples. To do so, we compile a theano function that takes as one 
step and aplly this function iteratively for a large number of steps, 
plotting the samples drawn at every 1000 step.

.. code-block:: python

    # the sample at the end of the channel is returned by ``gibbs_1`` as 
    # its second output; note that this is computed as a binomial draw, 
    # therefore it is formed of ints (0 and 1) and therefore needs to 
    # be converted to the same dtype as ``persistent_chain``
    chain_step_sample = T.cast(rbm.gibbs_1(persistent_chain)[1], dtype =
                                                    theano.config.floatX)
    # construct the function that implements our persistent chain 
    sample_fn = theano.function([], chain_step_sample, 
                      updates = { persistent_chain:chain_step_sample })

    # sample the RBM, plotting every `plot_every`-th sample; do this 
    # until you plot at least `n_samples`
    n_samples = 10
    plot_every = 1000

    for idx in xrange(n_samples):
        # do `plot_every` intermediate samplings of which we do not care
        for jdx in  xrange(plot_every):
            sample_fn()
        # construct image
        image = PIL.Image.fromarray(tile_raster_images( 
                                         X          = persistent_chain.value,
                                         img_shape  = (28,28),
                                         tile_shape = (10,10),
                                         tile_spacing = (1,1) ) )
        print ' ... plotting sample ', idx
        image.save('sample_%i_step_%i.png'%(idx,idx*jdx))





Results
+++++++


 Training took 20.862 minutes for 15 epochs with learning rate 0.1 .


Picture below shows the filters after 15 epochs : 

.. image:: images/filters_at_epoch_14.png
    :align: center






