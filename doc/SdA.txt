.. _SdA:

Stacked Denoising Autoencoders (SdA)
====================================

.. note::
  This section assumes the reader has already read through :doc:`logreg`
  and :doc:`mlp`. Additionally it uses the following Theano functions
  and concepts : TODO


The Stacked Denoising Autoencoder (SdA) is an extension of the stacked 
autoencoder [Bengio07]_ and it was introduced in [Vincent08]_. We will start the 
tutorial with a short discussion on :ref:`autoencoders`
and then move on to how classical
autoencoders are extended to denoising autoencoders (:ref:`DA`).

.. _autoencoders:

Autoencoders
+++++++++++++

See section 4.6 of [Bengio09]_ for an overview of auto-encoders.
An autoencoder takes an input :math:`\mathbf{x} \in [0,1]^d` and first 
maps it (with an *encoder*) to a hidden representation :math:`\mathbf{y} \in [0,1]^{d'}` 
through a deterministic mapping, e.g.:

.. math::
  
  \mathbf{y} = s(\mathbf{W}\mathbf{x} + \mathbf{b})

Where :math:`s` is a non-linearity such as the sigmoid.
The latent representation :math:`\mathbf{y}`, or **code** is then mapped back (with a *decoder*) into a
**reconstruction** :math:`\mathbf{z}` of same shape as
:math:`\mathbf{x}` through a similar transformation, e.g.:

.. math::

  \mathbf{z} = s(\mathbf{W'}\mathbf{y} + \mathbf{b'})

where ' does not indicate transpose, and
:math:`\mathbf{z}` should be seen as a prediction of :math:`\mathbf{x}`, given the code :math:`\mathbf{y}`.
The weight matrix :math:`\mathbf{W'}` of the reverse mapping may be
optionally constrained by :math:`\mathbf{W'} = \mathbf{W}^T`, which is
an instance of *tied weights*. The parameters of this model (namely 
:math:`\mathbf{W}`, :math:`\mathbf{b}`, 
:math:`\mathbf{b'}` and, if one doesn't use tied weights, also 
:math:`\mathbf{W'}`) are optimized such that the average reconstruction 
error is minimized. The reconstruction error can be measured in many ways, depending
on the appropriate distributional assumptions on the input given the code, e.g., using the 
traditional *squared error* :math:`L(\mathbf{x}, \mathbf{z}) = || \mathbf{x} - \mathbf{z} ||^2`, 
or if the input is interpreted as either bit vectors or vectors of 
bit probabilities by the reconstruction *cross-entropy* defined as : 

.. math::

  L_{H} (\mathbf{x}, \mathbf{z}) = - \sum^d_{k=1}[\mathbf{x}_k \log
          \mathbf{z}_k + (1 - \mathbf{x}_k)\log(1 - \mathbf{z}_k)] 

The hope is that the code :math:`\mathbf{y}` is a distributed representation
that captures the coordinates along the main factors of variation in the data
(similarly to how the projection on principal components captures the main factors
of variation in the data).
Because :math:`\mathbf{y}` is viewed as a lossy compression of :math:`\mathbf{x}`, it cannot
be a good compression (with small loss) for all :math:`\mathbf{x}`, so learning
drives it to be one that is a good compression in particular for training
examples, and hopefully for others as well, but not for arbitrary inputs.
That is the sense in which an auto-encoder generalizes: it gives low reconstruction
error to test examples from the same distribution as the training examples,
but generally high reconstruction error to uniformly chosen configurations of the
input vector.

If there is one linear hidden layer (the code) and
the mean squared error criterion is used to train the network, then the :math:`k`
hidden units learn to project the input in the span of the first :math:`k`
principal components of the data. If the hidden
layer is non-linear, the auto-encoder behaves differently from PCA,
with the ability to capture multi-modal aspects of the input
distribution. The departure from PCA becomes even more important when
we consider *stacking multiple encoders* (and their corresponding decoders)
when building a deep auto-encoder [Hinton06]_.

We want to implement an auto-encoder using Theano, in the form of a class,
that could be afterwards used in constructing a stacked autoencoder. The
first step is to create shared variables for the parameters of the 
autoencoder ( :math:`\mathbf{W}`, :math:`\mathbf{b}` and 
:math:`\mathbf{b'}`, since we are using tied weights in this tutorial ): 



.. code-block:: python
 
    class AutoEncoder(object):

        def __init__(self, n_visible= 784, n_hidden= 500, input = None):

          # initial values for weights and biases
          # note : W' was written as `W_prime` and b' as `b_prime`

          # W is initialized with `initial_W` which is uniformly sampled
          # from -6./sqrt(n_visible+n_hidden) and 6./sqrt(n_hidden+n_visible)
          # the output of uniform if converted using asarray to dtype 
          # theano.config.floatX so that the code is runable on GPU
          initial_W = numpy.asarray( numpy.random.uniform( \
              low = -numpy.sqrt(6./(n_visible+n_hidden)), \
              high = numpy.sqrt(6./(n_visible+n_hidden)), \
              size = (n_visible, n_hidden)), dtype = theano.config.floatX)
          initial_b       = numpy.zeros(n_hidden)
          initial_b_prime= numpy.zeros(n_visible)
     
    
          # theano shared variables for weights and biases
          self.W       = theano.shared(value = initial_W,       name = "W")
          self.b       = theano.shared(value = initial_b,       name = "b")
          # tied weights, therefore W_prime is W transpose
          self.W_prime = W.T 
          self.b_prime = theano.shared(value = initial_b_prime, name = "b'")

Note that we pass the symbolic ``input``  to the autoencoder as a
parameter. This is such that later we can concatenate layers of 
autoencoders to form a deep network: the symbolic output (the :math:`\mathbf{y}` above, self.y 
in the code below) of
the k-th layer will be the symbolic input of the (k+1)-th.

Now we can express the computation of the latent representation and of the reconstructed
signal: 

.. code-block:: python

    self.y    = T.nnet.sigmoid(T.dot(self.x, self.W      ) + self.b)
    self.z    = T.nnet.sigmoid(T.dot(self.y, self.W_prime) + self.b_prime)
    # note : we sum over the size of a data point; if we are using minibatches,
    #        L will  be a vector, with one entry per example in minibatch 
    self.L    = - T.sum( self.x*T.log(self.z) + (1-self.x)*T.log(1-self.z), axis=1 ) 
    # note : L is now a vector, where each element is the cross-entropy cost 
    #        of the reconstruction of the corresponding example of the 
    #        minibatch. We need to compute the average of all these to get 
    #        the average cost over the minibatch 
    self.cost = T.mean(self.L)

Training the autoencoder can be done by iteratively updating the parameters ``W``, 
``b`` and ``b_prime``, e.g., by stochastic gradient descent, such that the 
reconstruction cost is approximately minimized.

.. code-block:: python

  train = theano.function( [x], cost, updates = { \
            self.W       : self.W       - T.grad(self.cost, self.W      )*learning_rate, 
            self.b       : self.b       - T.grad(self.cost, self.b      )*learning_rate,
            self.b_prime : self.b_prime - T.grad(self.cost, self.b_prime)*learning_rate})

Note that the training script for the stacked denoising autoencoder will be
slightly different. The above algorithm was used as a building block
(for unsupervised pre-training of each layer) in [Bengio07]
to build deep networks. The main idea of unsupervised pre-training is
the following: each layer of a deep network is first trained using a
local unsupervised criterion (such as minimizing reconstruction error
at each level);
afterwards, all the encoders parameters are used to initialize a deep 
supervised neural network, and all the parameters are jointly
fine-tuned to minimize the supervised cost function.

One serious potential issue with auto-encoders is that if there is no other
constraint besides minimizing the reconstruction error, 
then an auto-encoder with :math:`n` inputs and an
encoding of dimension at least :math:`n` could potentially just learn
the identity function, for which many encodings would be useless (e.g.,
just copying the input), i.e., the autoencoder would not differentiate
test examples (from the training distribution) from other input configurations.
Surprisingly, experiments reported in [Bengio07]_ nonetheless 
suggest that in practice, when trained with
stochastic gradient descent, non-linear auto-encoders with more hidden units
than inputs (called overcomplete) yield useful representations
(in the sense of classification error measured on a network taking this
representation in input). A simple explanation is based on the 
observation that stochastic gradient
descent with early stopping is similar to an L2 regularization of the
parameters. To achieve perfect reconstruction of continuous
inputs, a one-hidden layer auto-encoder with non-linear hidden units
(exactly like in the above code)
needs very small weights in the first (encoding) layer (to bring the non-linearity of
the hidden units in their linear regime) and very large weights in the
second (decoding) layer.
With binary inputs, very large weights are
also needed to completely minimize the reconstruction error. Since the
implicit or explicit regularization makes it difficult to reach
large-weight solutions, the optimization algorithm finds encodings which
only work well for examples similar to those in the training set, which is
what we want. It means that the representation is exploiting statistical
regularities present in the training set, rather than learning to
replicate the identity function.

There are different ways that an auto-encoder with more hidden units
than inputs could be prevented from learning the identity, and still
capture something useful about the input in its hidden representation.
One is the addition of sparsity (forcing many of the hidden units to
be zero or near-zero), and it has been exploited very successfully
by many [Ranzato07]_ [Lee08]_. Another is to add randomness in the transformation from
input to reconstruction. This is exploited in Restricted Boltzmann
Machines (discussed later in this tutorial), as well as in
Denoising Auto-Encoders, discussed below. 

.. _DA:

Denoising Autoencoders
++++++++++++++++++++++

The idea behind denoising autoencoders is simple. In order to force
the hidden layer to discover more robust features and prevent it
from simply learning the identity, we train the
autoencoder to *reconstruct the input from a corrupted version of it*.

The denoising auto-encoder is a stochastic version of the auto-encoder.
Intuitively, a denoising auto-encoder does two things: try to encode the
input (preserve the information about the input), and try to undo the
effect of a corruption process stochastically applied to the input of the
auto-encoder. The latter can only be done by capturing the statistical
dependencies between the inputs. The denoising
auto-encoder can be understood from different perspectives 
( the manifold learning perspective, 
stochastic operator perspective, 
bottom-up -- information theoretic perspective, 
top-down -- generative model perspective ), all of which are explained in 
[Vincent08]. 
See also section 7.2 of [Bengio09]_ for an overview of auto-encoders.

In [Vincent08], the stochastic corruption process
consists in randomly setting some of the inputs (as many as half of them)
to zero. Hence the denoising auto-encoder is trying to *predict the corrupted (i.e. missing)
values from the uncorrupted (i.e., non-missing) values*, for randomly selected subsets of
missing patterns. Note how being able to predict any subset of variables
from the rest is a sufficient condition for completely capturing the
joint distribution between a set of variables (this is how Gibbs
sampling works).

To convert the autoencoder class into a denoising autoencoder class, all we 
need to do is to add a stochastic corruption step operating on the input. The input can be
corrupted in many ways, but in this tutorial we will stick to the original 
corruption mechanism of randomly masking entries of the input by making
them zero. The code below 
does just that : 

.. code-block:: python

  from theano.tensor.shared_randomstreals import RandomStreams

  theano_rng = RandomStreams()
  corrupted_x = x * theano.rng.binomial(x.shape, 1, 0.9)

In the stacked autoencoder class (:ref:`stacked_autoencoders`) the
weights of the ``dA`` class have to be shared with those of an
corresponding sigmoid layer. For this reason, the constructor of the ``dA`` also gets Theano
variables pointing to the shared parameters. If those parameters are left
to ``None``, new ones will be constructed.

The final denoising autoencoder class becomes : 

.. code-block:: python

   class dA(object):

       def __init__(self, n_visible= 784, n_hidden= 500, corruption_level = 0.1, input = None, shared_W = None, shared_b = None):

          self.n_visible = n_visible
          self.n_hidden  = n_hidden
          
          
          # create a Theano random generator that gives symbolic random values
          theano_rng = RandomStreams()
          # create a numpy random generator
          numpy_rng = numpy.random.RandomState()
    
          if shared_W != None and shared_b != None : 
              self.W = shared_W
              self.b = shared_b
          else:
              # initial values for weights and biases
              # note : W' was written as `W_prime` and b' as `b_prime`
              
              # W is initialized with `initial_W` which is uniformely sampled
              # from -6./sqrt(n_visible+n_hidden) and 6./sqrt(n_hidden+n_visible)
              # the output of uniform if converted using asarray to dtype 
              # theano.config.floatX so that the code is runable on GPU
              initial_W = numpy.asarray( numpy.random.uniform( \
                  low = -numpy.sqrt(6./(n_hidden+n_visible)), \
                  high = numpy.sqrt(6./(n_hidden+n_visible)), \
                  size = (n_visible, n_hidden)), dtype = theano.config.floatX)
              initial_b       = numpy.zeros(n_hidden)
    
    
              # theano shared variables for weights and biases
              self.W       = theano.shared(value = initial_W,       name = "W")
              self.b       = theano.shared(value = initial_b,       name = "b")
    
 
          initial_b_prime= numpy.zeros(n_visible)
          # tied weights, therefore W_prime is W transpose
          self.W_prime = self.W.T 
          self.b_prime = theano.shared(value = initial_b_prime, name = "b'")

   
          # if no input is given, generate a variable representing the input
          if input == None : 
              # we use a matrix because we expect a minibatch of several examples,
              # each example being a row
              self.x = T.dmatrix(name = 'input') 
          else:
              self.x = input
          # keep 90% of the inputs the same and zero-out randomly selected subset of 10% of the inputs
          # note : first argument of theano.rng.binomial is the shape(size) of 
          #        random numbers that it should produce
          #        second argument is the number of trials 
          #        third argument is the probability of success of any trial
          #
          #        this will produce an array of 0s and 1s where 1 has a 
          #        probability of 1 - ``corruption_level`` and 0 with
          #        ``corruption_level``
          self.tilde_x  = theano_rng.binomial( self.x.shape,  1,  1 - corruption_level) * self.x
          self.y   = T.nnet.sigmoid(T.dot(self.tilde_x, self.W      ) + self.b)
          self.z        = T.nnet.sigmoid(T.dot(self.y, self.W_prime) + self.b_prime)
          self.L = - T.sum( self.x*T.log(self.z) + (1-self.x)*T.log(1-self.z), axis=1 ) 
          # note : L is now a vector, where each element is the cross-entropy cost 
          #        of the reconstruction of the corresponding example of the 
          #        minibatch. We need to compute the average of all these to get 
          #        the cost of the minibatch
          self.cost = T.mean(self.L)


          self.params = [ self.W, self.b, self.b_prime ]




.. _stacked_autoencoders:

Stacked Autoencoders
++++++++++++++++++++

The denoising autoencoders can be stacked to form a deep network by
feeding the latent representation (output code)
of the denoising auto-encoder found on the layer 
below as input to the current layer. The **unsupervised pre-training** of such an 
architecture is done one layer at a time. Each layer is trained as 
a denoising auto-encoder by minimizing the reconstruction of its input
(which is the output code of the previous layer).
Once the first :math:`k` layers 
are trained, we can train the :math:`k+1`-th layer because we can now 
compute the code or latent representation from the layer below. 
Once all layers are pre-trained, the network goes through a second stage
of training called **fine-tuning**. Here we consider **supervised fine-tuning**
where we want to minimize prediction error on a supervised task.
For this we first add a logistic regression 
layer on top of the network (more precisely on the output code of the
output layer). We then
train the entire network as we would train a multilayer 
perceptron. At this point, we only consider the encoding parts of
each auto-encoder.
This stage is supervised, since now we use the target class during
training (see the :ref:`mlp` for details on the multilayer perceptron).

This can be easily implemented in Theano, using the class defined
before for a denoising autoencoder. We can see the stacked denoising
autoencode as having two facades, one is a list of
autoencoders, the other is an MLP. During pre-training we use the first facade, i.e we treat our model
as a list of autoencoders, and train each autoencoder seperately. In the 
second stage of training, we use the second facade. These two
facedes are linked by the fact that the autoencoders and the sigmoid layers of 
the MLP share parameters, and the fact that autoencoders get as input latent
representations of intermediate layers of the MLP. 

.. code-block:: python

  class StackedAutoencoder():

     def __init__(self, train_set_x, train_set_y, batch_size, n_ins, 
                 hidden_layers_sizes, n_outs, 
                 corruption_levels, rng, pretrain_lr, finetune_lr):
        """ This class is made to support a variable number of layers. 

        :param train_set_x: symbolic variable pointing to the training dataset 

        :param train_set_y: symbolic variable pointing to the labels of the
        training dataset

        :param n_ins: dimension of the input to the sdA

        :param n_layers_sizes: intermidiate layers size, must contain 
        at least one value

        :param n_outs: dimension of the output of the network

        :param corruption_levels: amount of corruption to use for each 
        layer

        :param rng: numpy random number generator used to draw initial weights

        :param pretrain_lr: learning rate used during pre-trainnig stage

        :param finetune_lr: learning rate used during finetune stage
 
        self.layers             = []
        self.pretrain_functions = []
        self.params             = []
        self.n_layers           = len(hidden_layers_sizes)

        if len(hidden_layers_sizes) < 1 :
            raiseException (' You must have at least one hidden layer ')


        # allocate symbolic variables for the data
        index   = T.lscalar()    # index to a [mini]batch 
        self.x  = T.matrix('x')  # the data is presented as rasterized images
        self.y  = T.ivector('y') # the labels are presented as 1D vector of 
                                 # [int] labels

       """

``self.layers`` will store the sigmoid layers of the MLP facade, while
``self.pretrain_function`` will store  compiled Theano function to train 
each of the denoising autoencoder associated with the layers of the MLP. 
Because we compile our functions inside this class, we need to pass to
the constructor Theano variable pointing to our training 
set ( on which these functions will operate). 

Next step, we construct ``n_layers`` sigmoid layers (we use the
``SigmoidalLayer`` class introduced in :ref:`lenet`, with the only
modification that we replaced the non-linearity from ``tanh`` to the
logistic function :math:`s(x) = \frac{1}{1+e^{-x}}`) and ``n_layers``
denoising autoencoders, where ``n_layers`` is the depth of our model.
We link the sigmoid layers such that they form an MLP, and construct
each denoising autoencoder such that they share the weight matrix and the 
bias of the encoding part with its corresponding sigmoid layer.

.. code-block:: python

        for i in xrange( self.n_layers ):
            # construct the sigmoidal layer

            # the size of the input is either the number of hidden units of 
            # the layer below or the input size if we are on the first layer
            if i == 0 :
                input_size = n_ins
            else:
                input_size = hidden_layers_sizes[i-1]

            # the input to this layer is either the activation of the hidden
            # layer below or the input of the SdA if you are on the first
            # layer
            if i == 0 : 
                layer_input = self.x
            else:
                layer_input = self.layers[-1].output

            layer = SigmoidalLayer(rng, layer_input, input_size, 
                                   hidden_layers_sizes[i] )
            # add the layer to the 
            self.layers += [layer]
            self.params += layer.params
        
            # Construct a denoising autoencoder that shared weights with this
            # layer
            dA_layer = dA(input_size, hidden_layers_sizes[i], \
                          corruption_level = corruption_levels[0],\
                          input = layer_input, \
                          shared_W = layer.W, shared_b = layer.b)
 

We do not need the ``dA_layer``, since we have pointers to all
parameters in ``layer``. Do only thing that we need from ``dA_layer`` is 
a function that we can call over the training set in order to train the 
autoencoder. The next few lines of code compile such a function. The
function is added to our list of functions. Note that the order in this
list is important, because pre-training has to be done starting from 
first layer to the last. 

.. code-block:: python 

            # Construct a function that trains this dA
            # compute gradients of layer parameters
            gparams = T.grad(dA_layer.cost, dA_layer.params)
            # compute the list of updates
            updates = {}
            for param, gparam in zip(dA_layer.params, gparams):
                updates[param] = param - gparam * pretrain_lr
            
            # create a function that trains the dA
            update_fn = theano.function([index], dA_layer.cost, \
                  updates = updates,
                  givens = { 
                     self.x : train_set_x[index*batch_size:(index+1)*batch_size]})
            # collect this function into a list
            self.pretrain_functions += [update_fn]



All we need now is to add the logistic layer on top of the sigmoid
layers such that we have an MLP. We will 
use the ``LogisticRegression`` class introduced in :ref:`logreg`. Since
we already have Theano variables pointing to our training dataset we
will also construct a training function for the MLP (that we will use
later in the fine-tunining stage). 

.. code-block:: python

        # We now need to add a logistic layer on top of the MLP
        self.logLayer = LogisticRegression(\
                         input = self.layers[-1].output,\
                         n_in = hidden_layers_sizes[-1], n_out = n_outs)

        self.params += self.logLayer.params
        # construct a function that implements one step of finetunining

        # compute the cost, defined as the negative log likelihood 
        cost = self.logLayer.negative_log_likelihood(self.y)
        # compute the gradients with respect to the model parameters
        gparams = T.grad(cost, self.params)
        # compute list of updates
        updates = {}
        for param,gparam in zip(self.params, gparams):
            updates[param] = param - gparam*finetune_lr
            
        self.finetune = theano.function([index], cost, 
                updates = updates,
                givens = {
                  self.x : train_set_x[index*batch_size:(index+1)*batch_size],
                  self.y : train_set_y[index*batch_size:(index+1)*batch_size]} )

        # symbolic variable that points to the number of errors made on the
        # minibatch given by self.x and self.y

        self.errors = self.logLayer.errors(self.y)





Putting it all together
+++++++++++++++++++++++

The few lines of code below constructs the stacked denoising
autoencoder : 

.. code-block:: python 


    # construct the stacked denoising autoencoder class
    classifier = SdA( train_set_x=train_set_x, train_set_y = train_set_y,\
                      batch_size = batch_size, n_ins=28*28, \
                      hidden_layers_sizes = [1000, 1000, 1000], n_outs=10, \
                      corruption_levels = [ 0.2, 0.2, 0.2],\
                      rng = numpy.random.RandomState(1234),\
                      pretrain_lr = pretrain_lr, finetune_lr = learning_rate )


There are two stages in training this network, a layer wise pre-training and 
fine-tuning afterwards. 

For the pre-training stage, we will loop over all the layers of the
network and apply the autoencode training function for a fixed number of 
epochs given by ``pretraining_epochs``


.. code-block:: python

    start_time = time.clock()  
    ## Pre-train layer-wise 
    for i in xrange(classifier.n_layers):
        # go through pretraining epochs 
        for epoch in xrange(pretraining_epochs):
            # go through the training set
            for batch_index in xrange(n_train_batches):
                c = classifier.pretrain_functions[i](batch_index)
            print 'Pre-training layer %i, epoch %d, cost '%(i,epoch),c
 
    end_time = time.clock()


The fine-tuning loop is very similar with the one in the :ref:`mlp`, the
only difference is that we will use now the ``finetune`` function that 
we compiled in the ``SdA`` class instead of a ``train_model`` function 
used in the other tutorials.




Running the Code
++++++++++++++++

The user can run the code by calling:

.. code-block:: bash
  
  python code/SdA.py

By default the code runs 15 pre-training epochs for each layer, with 
a corruption level of 0.1 and a learning rate of 0.1. Pre-training takes
78.88 minutes. Fine-tuning is completed after 32 epochs in 65.89 
minutes and results  in a validation score of 1.7 %, with a test 
performace of 1.65 %.


References
++++++++++

.. [Hinton06] `Reducing the Dimensionality of Data with Neural Networks <http://www.cs.toronto.edu/~rsalakhu/papers/science.pdf>`_, G.E. Hinton and R.R. Salakhutdinov,  Science, 28 July 2006, Vol. 313. no. 5786, pp. 504 - 507.

.. [Bengio07] `Greedy Layer-Wise Training of Deep Networks <http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/190>`_, Y. Bengio, P. Lamblin, D. Popovici and H. Larochelle, in Advances in Neural Information Processing Systems 19 (NIPS'06), pages  153-160, MIT Press 2007.

.. [Ranzato07] `Efficient Learning of Sparse Representations with an Energy-Based Model <http://yann.lecun.com/exdb/publis/pdf/ranzato-06.pdf>`_, M.A. Ranzato, C. Poultney, S. Chopra and Y. LeCun, in J. Platt et al. (Eds), Advances in Neural Information Processing Systems (NIPS 2006), MIT Press, 2007.

.. [Lee08] `Sparse deep belief net model for visual area V2 <http://www.stanford.edu/~hllee/nips07-sparseDBN.pdf>`_, H. Lee, C. Ekanadham, and A.Y. Ng., in Advances in Neural Information Processing Systems (NIPS) 20, 2008.

.. [Vincent08] `Extracting and Composing Robust Features with Denoising Autoencoders <http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/217>`_, P. Vincent, H. Larochelle Y. Bengio and P.A. Manzagol,  Proceedings of the Twenty-fifth International Conference on Machine Learning (ICML'08), pages 1096 - 1103, ACM, 2008.

.. [Bengio09] `Learning deep architectures for AI <http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/239>`_, Y. Bengio,  Foundations and Trends in Machine Learning 1(2) pages 1-127.

