Convolutional Neural Networks (LeNet)
=====================================

.. note::
    This section assumes the reader has already read through :doc:`logreg` and
    :doc:`mlp`. Additionally, it uses the following new Theano functions and
    concepts: TODO

Motivation
++++++++++

Convolutional Neural Networks (CNN) are variants of MLPs which are inspired from
biology. From Hubel and Wiesel's early work on the cat's visual cortex [Hubel]_,
we know there exists a complex arrangement of cells within the visual cortex.
These cells are sensitive to small sub-regions of the input space, called a
**receptive field**, and are tiled in such a way as to cover the entire visual
field. These filters are local in input space and are thus better suited to
exploit the strong local correlation present in natural images.

Additionally, two basic cell types have been identified: simple cells (S) and
complex cells (C). Simple cells (S) respond maximally to specific edge-like
stimulus patterns within their receptive field. Complex cells (C) have larger
receptive fields and are locally invariant to the exact position of the
stimulus.

The visual cortex being the most powerful "vision" system in existence, it
seems natural to emulate its behavior. Many such neurally inspired models can be
found in the litterature. To name a few: the NeoCognitron [Fukushima]_, HMAX
[Serre]_ and LeNet-5 [LeCun]_, which will be the focus of this tutorial.


The Model
+++++++++

Sparse Connectivity
-------------------

CNNs exploit local correlation by enforcing a local connectivity pattern between
neurons of adjacent layers. The input hidden units in the m-th layer are
connected to a local subset of units in the (m-1)-th layer, which are spatially
contiguous. We can illustrate this graphically as follows:

.. figure:: images/sparse_1D_nn.png
    :align: center

In the above, units have receptive fields of width 3 and are thus only
connected to 3 adjacent neurons in the layer below. The architecture thus
confines the learnt filters to be local. As shown above, stacking many such
layers leads to filters which become increasingly "global" however (i.e
spanning a larger region of pixel space). For example, the unit in hidden
layer (m+1) can encode a non-linear feature of width 5 (in terms of pixel
space).

Shared Weights
--------------

In CNNs, each sparse filter :math:`h_i` is additionally replicated across the
entire visual field. These "replicated" units form a **feature map**, which
share the same parametrization, i.e. the same weight vector and the same bias.

.. figure:: images/conv_1D_nn.png
    :align: center

In the above figure, we show 3 hidden units belonging to the same feature map.
Weights of the same color are shared. Learning these weights involves a new
spin on the chain rule of derivation: we simply sum over the gradients
emanating from the same feature map.

Replicating units in this way allows for features to be detected regardless of
their position in the visual field. Conceptually, a feature map is obtained by
convolving the input image with a linear filter, applying a bias term, followed by
a non-linearity. We denote the K-th feature map at a given layer as
:math:`h^k`, whose filters are determined by the weights :math:`W^k` and bias
:math:`b_k`, a feature map is obtained as follows:

.. math::
    h^k_{ij} = \sigma ( (W^k * x)_{ij} + b_k ).

.. Note:: 
    Recall the following definition of convolution for a 1D signal.
    :math:`o[n] = f[n]*g[n] = \sum_{u=-\infty}^{\infty} f[u] g[u-n] = \sum_{u=-\infty}^{\infty} f[n-u] g[u]`.

    This can be extended to 2D as follows:
    :math:`o[m,n] = f[m,n]*g[m,n] = \sum_{u=-\infty}^{\infty} \sum_{v=-\infty}^{\infty} f[u,v] g[u-m,v-n]`.

The set of all feature maps, :math:`\{h^(k), k=0..K\}`, forms a hidden layer. 
The weights :math:`W` of this layer, are parametrized as a 4D tensor and the
biases :math:`b` as a vector. This is best illustrated as follows:

.. figure:: images/cnn_explained.png
    :align: center

In the above figure, we show two layers of a CNN, containing 4 feature maps at
layer (m-1) and 2 feature maps at layer m: :math:`h^0` and :math:`h^1`. Pixels
in :math:`h^0` and :math:`h^1` (outlined as blue and red squares) are computed from
pixels of layer (m-1) which fall within their 2x2 receptive field (shown as
colored rectangles). Notice how the receptive field spans all four feature
maps. 
Each weight, :math:`W^{kl}_{ij}` thus denotes the weight connecting each pixel
of the k-th feature map at layer m, with the pixel at coordinates (i,j) of the
l-th feature map of layer (m-1). 


MaxPooling
----------

LeNet
-----

.. image:: images/mylenet.png
    :align: center


Going from MLP to convolutional MLP
+++++++++++++++++++++++++++++++++++


Putting it All Together
+++++++++++++++++++++++


.. Note:: TODO introduce API for sparse filters

References
+++++++++++++++++++++++

.. [Hubel] Hubel, D. and Wiesel, T. (1968). Receptive fields and functional architecture of monkey striate cortex. Journal of Physiology (London), 195, 215–243.

.. [Fukushima] Fukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological Cybernetics, 36, 193–202.

.. [Serre] Serre, T., Wolf, L., Bileschi, S., and Riesenhuber, M. (2007).  Robust object recog- nition with cortex-like mechanisms. IEEE Trans. Pattern Anal. Mach. Intell., 29(3), 411–426. Member-Poggio, Tomaso.

.. [LeCun] LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. (1998d).  Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278–2324.

.. rubric:: Footnotes

.. [#f1] For clarity, we use the word "unit" or "neuron" to refer to the
         artificial neuron and "cell" to refer to the biological neuron.


